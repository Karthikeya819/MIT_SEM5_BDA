{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Week4Practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('../../Week4/datasets/movie_reviews.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+------------------+\n",
      "|userId|movieId|rating|            review|\n",
      "+------+-------+------+------------------+\n",
      "|    92|    176|   4.6|  Highly recommend|\n",
      "|    30|     57|   2.5|           Not bad|\n",
      "|    62|     64|   2.2|Average experience|\n",
      "|    64|    173|   2.1|Average experience|\n",
      "|    49|     44|   3.5|  Highly recommend|\n",
      "+------+-------+------+------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- review: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df.randomSplit([0.75, 0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",rank=10, maxIter=10, regParam=0.1, coldStartStrategy=\"drop\", nonnegative=True)\n",
    "# passing coldSatrtStrategy is imp deafault value is 'nan' whole Rmse will be fucked\n",
    "model = als.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+------------------+----------+\n",
      "|userId|movieId|rating|            review|prediction|\n",
      "+------+-------+------+------------------+----------+\n",
      "|    31|     51|   1.6|   Could be better| 2.9769402|\n",
      "|    31|    139|   1.0|          Terrible| 2.5144107|\n",
      "|    31|    189|   4.8|  Highly recommend|  1.269039|\n",
      "|    85|     29|   4.5|  Highly recommend| 2.9175968|\n",
      "|    53|     94|   2.4|Average experience| 1.9511662|\n",
      "|    53|     99|   2.0|          Loved it| 3.0233846|\n",
      "|    34|     11|   2.2|     Waste of time|0.89292973|\n",
      "|    34|     88|   2.6|           Not bad|  2.092395|\n",
      "|    34|    102|   3.1| Amazing storyline|  2.903771|\n",
      "|    34|    178|   2.6|Average experience|  4.347064|\n",
      "|    34|    190|   3.1|       Good acting| 2.6881213|\n",
      "|    81|    153|   2.8|           Not bad|   2.20012|\n",
      "|    81|    174|   4.9|          Loved it| 2.6346138|\n",
      "|    28|     80|   2.6| Amazing storyline| 3.0419924|\n",
      "|    28|    116|   4.9|   Could be better| 1.0960867|\n",
      "|    76|    177|   3.4|          Loved it| 2.2487178|\n",
      "|    26|     16|   4.2|          Loved it| 1.8237829|\n",
      "|    26|     31|   1.6|          Terrible| 3.1331763|\n",
      "|    26|     71|   1.3|           Not bad| 1.2708076|\n",
      "|    26|    161|   4.6|   Could be better|0.84350395|\n",
      "+------+-------+------+------------------+----------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5025764380819233"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BdaEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
