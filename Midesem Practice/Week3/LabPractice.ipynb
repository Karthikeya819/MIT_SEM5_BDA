{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lower, trim, col, array_join, udf, when, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Week3Practice\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read.csv('../../Week3/datasets/lab3_1_dataset.csv', header=True, inferSchema=True)\n",
    "df2 = spark.read.csv('../../Week3/datasets/lab3_2_dataset.csv', header=True, inferSchema=True)\n",
    "\n",
    "df = df1.union(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.na.drop(\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('name', lower(trim(col('name'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol='name', outputCol='tokenization_name')\n",
    "df_tokens = tokenizer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+--------------------+--------------------+\n",
      "|  id|               name|             address|   tokenization_name|\n",
      "+----+-------------------+--------------------+--------------------+\n",
      "|1859|         nkev koquo|1087 Uxkgk St, Zw...|       [nkev, koquo]|\n",
      "|1402|      awdeltx flswj|1313 Bysqtepcyb S...|    [awdeltx, flswj]|\n",
      "|3503|      zvgk qmnjjfub|4451 Uymmthnzp St...|    [zvgk, qmnjjfub]|\n",
      "|1009|     suaxud ybukuxq|4793 Fodikswks St...|   [suaxud, ybukuxq]|\n",
      "| 276|    bdiolpnl iduwpc|3640 Hrfulh St, C...|  [bdiolpnl, iduwpc]|\n",
      "|4600|       mrada gsxapz|7676 Sngqs St, Ut...|     [mrada, gsxapz]|\n",
      "| 580|       hiwz zvsxqmr|1884 Guaxszlv St,...|     [hiwz, zvsxqmr]|\n",
      "|4861|       wpk gfduhflq|7724 Etqegoijrf S...|     [wpk, gfduhflq]|\n",
      "|1433|       udfzl woqmam|5479 Modamxtaxi S...|     [udfzl, woqmam]|\n",
      "|1641|    mjympmb zovjoib|2881 Lmulkkwj St,...|  [mjympmb, zovjoib]|\n",
      "|1248|bqplwedo neydmdiwgg|5237 Zhnthymzpq S...|[bqplwedo, neydmd...|\n",
      "|3973|    vlqthxhj drtueb|5392 Qirjqw St, H...|  [vlqthxhj, drtueb]|\n",
      "|2394|     ojhcxkb pjpvyf|7145 Zuslr St, Ynhwi|   [ojhcxkb, pjpvyf]|\n",
      "|4370|      rabges phtykl|8847 Stwkgddu St,...|    [rabges, phtykl]|\n",
      "|2831|      eaa akzarzwfx|5923 Xpwn St, Hopyrv|    [eaa, akzarzwfx]|\n",
      "|4489|        fzqma mlsaw|4608 Xxel St, Wir...|      [fzqma, mlsaw]|\n",
      "|4766|  ykqtwp wjqwgmlzds|4138 Kqmsqfpb St,...|[ykqtwp, wjqwgmlzds]|\n",
      "|3660|    lbmiw rverewfad|3374 Rpmxojoy St,...|  [lbmiw, rverewfad]|\n",
      "|3537|  dilhbsd sngfgxkys| 1933 Epla St, Vpbua|[dilhbsd, sngfgxkys]|\n",
      "|3971|    eztye pkfypkmvr|4817 Oaculqcw St,...|  [eztye, pkfypkmvr]|\n",
      "+----+-------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df_tokens.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[PATH_ALREADY_EXISTS] Path file:/home/karthikeya/Desktop/sem5/MIT_SEM5_BDA/Midesem Practice/Week3/tokenized_data already exists. Set mode as \"overwrite\" to overwrite the existing path. SQLSTATE: 42K04",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_tokens\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtokenization_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marray_join\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtokenization_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtokenized_data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/sem5/MIT_SEM5_BDA/BdaEnv/lib/python3.10/site-packages/pyspark/sql/readwriter.py:2146\u001b[0m, in \u001b[0;36mDataFrameWriter.csv\u001b[0;34m(self, path, mode, compression, sep, quote, escape, header, nullValue, escapeQuotes, quoteAll, dateFormat, timestampFormat, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, charToEscapeQuoteEscaping, encoding, emptyValue, lineSep)\u001b[0m\n\u001b[1;32m   2127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode(mode)\n\u001b[1;32m   2128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(\n\u001b[1;32m   2129\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[1;32m   2130\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2144\u001b[0m     lineSep\u001b[38;5;241m=\u001b[39mlineSep,\n\u001b[1;32m   2145\u001b[0m )\n\u001b[0;32m-> 2146\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/sem5/MIT_SEM5_BDA/BdaEnv/lib/python3.10/site-packages/py4j/java_gateway.py:1362\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1356\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1357\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1358\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1359\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1361\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1362\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1363\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1365\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1366\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/sem5/MIT_SEM5_BDA/BdaEnv/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:288\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    284\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [PATH_ALREADY_EXISTS] Path file:/home/karthikeya/Desktop/sem5/MIT_SEM5_BDA/Midesem Practice/Week3/tokenized_data already exists. Set mode as \"overwrite\" to overwrite the existing path. SQLSTATE: 42K04"
     ]
    }
   ],
   "source": [
    "df_tokens.withColumn('tokenization_name', array_join(col('tokenization_name'), ',')).write.csv('tokenized_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(tokens1, tokens2):\n",
    "    set1 = set(str(tokens1))\n",
    "    set2 = set(str(tokens2))\n",
    "\n",
    "    union = set1.union(set2)\n",
    "    intersection = set1.intersection(set2)\n",
    "\n",
    "    if not union:\n",
    "        return 0.0\n",
    "    \n",
    "    return float(len(intersection)) / len(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_udf = udf(jaccard_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pairs = df_tokens.alias('a').crossJoin(df_tokens.alias('b'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim = df_pairs.withColumn('jaccard_similarity_score', jaccard_udf(col('a.tokenization_name'), col('b.tokenization_name')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------------------------+\n",
      "|  id|  id|jaccard_similarity_score|\n",
      "+----+----+------------------------+\n",
      "|1859|1859|                     1.0|\n",
      "|1859|1402|      0.2857142857142857|\n",
      "|1859|3503|      0.5555555555555556|\n",
      "|1859|1009|      0.4444444444444444|\n",
      "|1859| 276|     0.42105263157894735|\n",
      "|1859|4600|     0.23809523809523808|\n",
      "|1859| 580|                    0.35|\n",
      "|1859|4861|     0.42105263157894735|\n",
      "|1859|1433|     0.42105263157894735|\n",
      "|1859|1641|      0.3684210526315789|\n",
      "+----+----+------------------------+\n",
      "only showing top 10 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_sim.select(['a.id', 'b.id', 'jaccard_similarity_score']).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim = df_sim.withColumn('label', when(col('a.id') == col('b.id'), lit(1)).otherwise(lit(0)))\n",
    "df_sim = df_sim.withColumn('pred_label', when(col('jaccard_similarity_score') > 0.5, lit(1)).otherwise(lit(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim = df_sim.withColumn('TP', when((col('pred_label') == 1) & (col('label') == 1), lit(1)).otherwise(lit(0)))\n",
    "df_sim = df_sim.withColumn('FP', when((col('pred_label') == 1) & (col('label') == 0), lit(1)).otherwise(lit(0)))\n",
    "df_sim = df_sim.withColumn('FN', when((col('pred_label') == 0) & (col('label') == 1), lit(1)).otherwise(lit(0)))\n",
    "df_sim = df_sim.withColumn('TN', when((col('pred_label') == 0) & (col('label') == 0), lit(1)).otherwise(lit(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "agg_result = df_sim.agg({\"TP\": \"sum\", \"FP\": \"sum\", \"FN\": \"sum\", \"TN\": \"sum\"}).collect()[0]\n",
    "\n",
    "TP = agg_result[\"sum(TP)\"]\n",
    "FP = agg_result[\"sum(FP)\"]\n",
    "FN = agg_result[\"sum(FN)\"]\n",
    "TN = agg_result[\"sum(TN)\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0016540165745975248, 1.0, 0.003302570642613388)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = TP/ (TP + FP)\n",
    "recall = TP/ (TP + FN)\n",
    "F1 = (2*precision*recall)/(precision + recall)\n",
    "\n",
    "precision, recall, F1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BdaEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
